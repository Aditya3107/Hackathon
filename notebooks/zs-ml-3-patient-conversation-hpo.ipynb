{"cells":[{"metadata":{},"cell_type":"markdown","source":"As we uploaded all solutions and realized, bag or words with logistic regression gives us the best results, with the score of 92.83, we will use hyperparameter optimization technique on the same model and will try to check if the model fine tunes and give more better results. "},{"metadata":{},"cell_type":"markdown","source":"First start with data preparation. We have already discussed in the previous notebooks, how we cleaned the datasets. "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"! pip install tldextract","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting tldextract\n  Downloading tldextract-3.1.0-py2.py3-none-any.whl (87 kB)\n\u001b[K     |████████████████████████████████| 87 kB 955 kB/s eta 0:00:01\n\u001b[?25hCollecting requests-file>=1.4\n  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\nRequirement already satisfied: requests>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from tldextract) (2.25.1)\nRequirement already satisfied: idna in /opt/conda/lib/python3.7/site-packages (from tldextract) (2.10)\nRequirement already satisfied: filelock>=3.0.8 in /opt/conda/lib/python3.7/site-packages (from tldextract) (3.0.12)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.1.0->tldextract) (2020.12.5)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.1.0->tldextract) (1.26.2)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.1.0->tldextract) (3.0.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from requests-file>=1.4->tldextract) (1.15.0)\nInstalling collected packages: requests-file, tldextract\nSuccessfully installed requests-file-1.5.1 tldextract-3.1.0\n\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tldextract import extract\nimport re,sys,pickle","execution_count":2,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"#nltk libraries\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nnltk.download('stopwords')\nstop=set(stopwords.words('english'))\nfrom nltk.stem.snowball import SnowballStemmer","execution_count":7,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","name":"stdout"}]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","execution_count":8,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/zsdataset/train.csv',encoding= 'ISO-8859-1')\ntest_df = pd.read_csv('../input/zsdataset/test.csv',encoding= 'ISO-8859-1')\n\n#extracts the url from the link, we will extract hostname only\ndef extract_url(x):\n    tsd, td, tsu = extract(x) # prints abc, hostname, com\n    return td\n\ndef classes_def(x):\n    if x ==  \"FACEBOOK\":\n        return \"Facebook\"\n    elif x == 'FORUMS':\n        return 'Forums'\n    elif x == 'BLOG':\n        return 'Blog'\n    elif x == 'YOUTUBE':\n        return 'Youtube'\n    else:\n        return 'Facebook'\n\ndef clean_text(x):\n    normalizedsentense = x.lower()\n    text = re.sub(r\"[^a-z']+\", ' ', normalizedsentense)\n    return text\n\n\nstemmer = SnowballStemmer('english')\ndef stemming(sentence):\n    word_list = nltk.word_tokenize(sentence)\n    stemmed_output = ' '.join([stemmer.stem(w) for w in word_list])\n    return stemmed_output\n\ntrain_df['Source']=train_df['Source'].apply(lambda x:classes_def(x))\ntest_df['Source']=test_df['Source'].apply(lambda x:classes_def(x))\ntrain_df[\"Host\"].fillna(train_df[\"Link\"], inplace=True)\ntest_df[\"Host\"].fillna(test_df[\"Link\"], inplace=True)\ntrain_df['Host']=train_df['Host'].apply(lambda x:extract_url(x))\ntest_df['Host']=test_df['Host'].apply(lambda x:extract_url(x))\ntrain_df.loc[train_df.Host == '' , 'Host'] = 'youtube'\n\ntrain_df = train_df.drop(['Link','time(GMT)','Title'],axis= 1)\ntest_df = test_df.drop(['Link','time(GMT)','Title'],axis= 1)\n\ntrain_df['Date(ET)'] = pd.to_datetime(train_df['Date(ET)'],errors='coerce').dt.date\ntest_df['Date(ET)'] = pd.to_datetime(test_df['Date(ET)'],errors='coerce').dt.date\n\ntrain_df['Time(ET)'] = pd.to_datetime(train_df['Time(ET)'],errors='coerce').dt.time\ntest_df['Time(ET)'] = pd.to_datetime(test_df['Time(ET)'],errors='coerce').dt.time\n\ntest_df.drop(columns = ['Index','Unnamed: 9'],inplace = True)\n\ntrain_df = train_df[train_df['TRANS_CONV_TEXT'].notna()]\n\ntrain_df['TRANS_CONV_TEXT']=train_df['TRANS_CONV_TEXT'].apply(lambda x:clean_text(x))\ntest_df['TRANS_CONV_TEXT']=test_df['TRANS_CONV_TEXT'].apply(lambda x:clean_text(x))\n\ntrain_df['TRANS_CONV_TEXT']=train_df['TRANS_CONV_TEXT'].apply(lambda x: stemming(x))\ntest_df['TRANS_CONV_TEXT']=test_df['TRANS_CONV_TEXT'].apply(lambda x: stemming(x))","execution_count":9,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"train_df.head()","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"   Source                Host    Date(ET)  Time(ET)  \\\n0  Forums          cafepharma  2016-06-15  13:58:00   \n1  Forums             patient  2016-05-07       NaT   \n2    Blog  abcnewsradioonline  2016-04-14  15:00:38   \n3  Forums       cancer-forums  2016-06-18  20:46:00   \n4  Forums            diyaudio  2016-06-15  03:26:00   \n\n                                     TRANS_CONV_TEXT  Patient_Tag  \n0  i do n't disagre with you in principl i 'm jus...            0  \n1  i am alway dizzi i get dizzi stand up so i hav...            1  \n2  axell bauer griffin filmmag new york queen lat...            0  \n3  i am and i have been throw up for about a year...            1  \n4  quot origin post by boyan silyavski wake up my...            0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Source</th>\n      <th>Host</th>\n      <th>Date(ET)</th>\n      <th>Time(ET)</th>\n      <th>TRANS_CONV_TEXT</th>\n      <th>Patient_Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Forums</td>\n      <td>cafepharma</td>\n      <td>2016-06-15</td>\n      <td>13:58:00</td>\n      <td>i do n't disagre with you in principl i 'm jus...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Forums</td>\n      <td>patient</td>\n      <td>2016-05-07</td>\n      <td>NaT</td>\n      <td>i am alway dizzi i get dizzi stand up so i hav...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Blog</td>\n      <td>abcnewsradioonline</td>\n      <td>2016-04-14</td>\n      <td>15:00:38</td>\n      <td>axell bauer griffin filmmag new york queen lat...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Forums</td>\n      <td>cancer-forums</td>\n      <td>2016-06-18</td>\n      <td>20:46:00</td>\n      <td>i am and i have been throw up for about a year...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Forums</td>\n      <td>diyaudio</td>\n      <td>2016-06-15</td>\n      <td>03:26:00</td>\n      <td>quot origin post by boyan silyavski wake up my...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"test_df.head()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"   Source          Host    Date(ET)  Time(ET)  \\\n0    Blog   uhmagonline  2016-07-30  00:41:23   \n1  Forums          yuku  2016-06-20  00:07:30   \n2    Blog      blogspot  2016-06-15  15:44:00   \n3  Forums  healthboards  2016-07-17  19:41:00   \n4    Blog  sciencecodex  2016-04-04  15:30:45   \n\n                                     TRANS_CONV_TEXT  \n0  babi slice the son of the late kimbo slice has...  \n1  p font face san serif size i have had both sil...  \n2  previous sodium glucos cotransport sglt inhibi...  \n3  hello i suffer from congest heart failur due t...  \n4  a daili dose of vitamin d improv heart functio...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Source</th>\n      <th>Host</th>\n      <th>Date(ET)</th>\n      <th>Time(ET)</th>\n      <th>TRANS_CONV_TEXT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Blog</td>\n      <td>uhmagonline</td>\n      <td>2016-07-30</td>\n      <td>00:41:23</td>\n      <td>babi slice the son of the late kimbo slice has...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Forums</td>\n      <td>yuku</td>\n      <td>2016-06-20</td>\n      <td>00:07:30</td>\n      <td>p font face san serif size i have had both sil...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Blog</td>\n      <td>blogspot</td>\n      <td>2016-06-15</td>\n      <td>15:44:00</td>\n      <td>previous sodium glucos cotransport sglt inhibi...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Forums</td>\n      <td>healthboards</td>\n      <td>2016-07-17</td>\n      <td>19:41:00</td>\n      <td>hello i suffer from congest heart failur due t...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Blog</td>\n      <td>sciencecodex</td>\n      <td>2016-04-04</td>\n      <td>15:30:45</td>\n      <td>a daili dose of vitamin d improv heart functio...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"In Logistic Regression there are 2 papameters we can consider for hyperparamter tuning. \n* penalty{‘l1’, ‘l2’, ‘elasticnet’, ‘none’}, default=’l2’ Used to specify the norm used in the penalization. The ‘newton-cg’, ‘sag’ and ‘lbfgs’ solvers support only l2 penalties. ‘elasticnet’ is only supported by the ‘saga’ solver. If ‘none’ (not supported by the liblinear solver), no regularization is applied.\n* Cfloat, default=1.0, Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization.\n\n* C values [0.001, 0.01, 0.1, 1 , 10 ,100]\n* Also, look in the above point 1, when there is l2 penelty we can apply solvers ['newton-cg', 'lbfgs', 'liblinear']"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"df_hpo = train_df[['TRANS_CONV_TEXT','Patient_Tag']]\ndf_hpo.head()","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"                                     TRANS_CONV_TEXT  Patient_Tag\n0  i do n't disagre with you in principl i 'm jus...            0\n1  i am alway dizzi i get dizzi stand up so i hav...            1\n2  axell bauer griffin filmmag new york queen lat...            0\n3  i am and i have been throw up for about a year...            1\n4  quot origin post by boyan silyavski wake up my...            0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TRANS_CONV_TEXT</th>\n      <th>Patient_Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>i do n't disagre with you in principl i 'm jus...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i am alway dizzi i get dizzi stand up so i hav...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>axell bauer griffin filmmag new york queen lat...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>i am and i have been throw up for about a year...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>quot origin post by boyan silyavski wake up my...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"scrolled":false},"cell_type":"code","source":"from sklearn import linear_model\nfrom sklearn import metrics\nfrom sklearn import model_selection\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import make_scorer\n\nif __name__ ==\"__main__\":\n    \n    \n    #randomize the data\n    df_hpo = df_hpo.sample(frac = 1).reset_index(drop =True)\n    \n    #initialize the count vector tokenizer with NLTK word tokenize\n    count_vec = CountVectorizer(tokenizer = word_tokenize, token_pattern = None)\n    \n    #fit the count vector\n    count_vec.fit(df_hpo.TRANS_CONV_TEXT)\n    pickle.dump(count_vec, open(\"count_vectorizer.pickle\", \"wb\")) \n    \n    #transform the training and validation data reviews\n    X = count_vec.transform(df_hpo.TRANS_CONV_TEXT)\n    y = df_hpo.Patient_Tag.values\n    \n    classifier = linear_model.LogisticRegression()\n    param_grid = {\n                    \"solver\": ['newton-cg','lbfgs','sag','saga'],\n                    \"penalty\": ['l2'],\n                    \"C\": [100, 10, 1.0, 0.1, 0.01, 0.001]\n                }\n    roc_auc_weighted = metrics.make_scorer(metrics.roc_auc_score, average='weighted')\n    model = model_selection.GridSearchCV(\n                        estimator=classifier,\n                        param_grid=param_grid,\n                        scoring=roc_auc_weighted,\n                        verbose=10,\n                        n_jobs=1,\n                        cv=5\n                        ) \n  \n    model.fit(X, y)\n    print(f\"Best score: {model.best_score_}\")\n    print(\"Best parameters set:\")\n    best_parameters = model.best_estimator_.get_params()\n    for param_name in sorted(param_grid.keys()):\n        print(f\"\\t{param_name}: {best_parameters[param_name]}\")\n    \n","execution_count":39,"outputs":[{"output_type":"stream","text":"Fitting 5 folds for each of 24 candidates, totalling 120 fits\n[CV] C=100, penalty=l2, solver=newton-cg .............................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","name":"stderr"},{"output_type":"stream","text":"[CV] . C=100, penalty=l2, solver=newton-cg, score=0.840, total=   0.2s\n[CV] C=100, penalty=l2, solver=newton-cg .............................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] . C=100, penalty=l2, solver=newton-cg, score=0.838, total=   0.3s\n[CV] C=100, penalty=l2, solver=newton-cg .............................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] . C=100, penalty=l2, solver=newton-cg, score=0.887, total=   0.2s\n[CV] C=100, penalty=l2, solver=newton-cg .............................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.7s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] . C=100, penalty=l2, solver=newton-cg, score=0.845, total=   0.2s\n[CV] C=100, penalty=l2, solver=newton-cg .............................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.9s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] . C=100, penalty=l2, solver=newton-cg, score=0.845, total=   0.2s\n[CV] C=100, penalty=l2, solver=lbfgs .................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.2s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ..... C=100, penalty=l2, solver=lbfgs, score=0.840, total=   0.5s\n[CV] C=100, penalty=l2, solver=lbfgs .................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    1.7s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ..... C=100, penalty=l2, solver=lbfgs, score=0.841, total=   0.4s\n[CV] C=100, penalty=l2, solver=lbfgs .................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    2.0s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ..... C=100, penalty=l2, solver=lbfgs, score=0.887, total=   0.4s\n[CV] C=100, penalty=l2, solver=lbfgs .................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    2.4s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ..... C=100, penalty=l2, solver=lbfgs, score=0.848, total=   0.5s\n[CV] C=100, penalty=l2, solver=lbfgs .................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    2.9s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ..... C=100, penalty=l2, solver=lbfgs, score=0.845, total=   0.4s\n[CV] C=100, penalty=l2, solver=sag ...................................\n[CV] ....... C=100, penalty=l2, solver=sag, score=0.858, total=   0.2s\n[CV] C=100, penalty=l2, solver=sag ...................................\n[CV] ....... C=100, penalty=l2, solver=sag, score=0.854, total=   0.1s\n[CV] C=100, penalty=l2, solver=sag ...................................\n[CV] ....... C=100, penalty=l2, solver=sag, score=0.841, total=   0.1s\n[CV] C=100, penalty=l2, solver=sag ...................................\n[CV] ....... C=100, penalty=l2, solver=sag, score=0.868, total=   0.1s\n[CV] C=100, penalty=l2, solver=sag ...................................\n[CV] ....... C=100, penalty=l2, solver=sag, score=0.780, total=   0.1s\n[CV] C=100, penalty=l2, solver=saga ..................................\n[CV] ...... C=100, penalty=l2, solver=saga, score=0.840, total=   0.2s\n[CV] C=100, penalty=l2, solver=saga ..................................\n[CV] ...... C=100, penalty=l2, solver=saga, score=0.843, total=   0.2s\n[CV] C=100, penalty=l2, solver=saga ..................................\n[CV] ...... C=100, penalty=l2, solver=saga, score=0.838, total=   0.2s\n[CV] C=100, penalty=l2, solver=saga ..................................\n[CV] ...... C=100, penalty=l2, solver=saga, score=0.847, total=   0.2s\n[CV] C=100, penalty=l2, solver=saga ..................................\n[CV] ...... C=100, penalty=l2, solver=saga, score=0.791, total=   0.2s\n[CV] C=10, penalty=l2, solver=newton-cg ..............................\n[CV] .. C=10, penalty=l2, solver=newton-cg, score=0.840, total=   0.2s\n[CV] C=10, penalty=l2, solver=newton-cg ..............................\n[CV] .. C=10, penalty=l2, solver=newton-cg, score=0.851, total=   0.2s\n[CV] C=10, penalty=l2, solver=newton-cg ..............................\n[CV] .. C=10, penalty=l2, solver=newton-cg, score=0.884, total=   0.2s\n[CV] C=10, penalty=l2, solver=newton-cg ..............................\n[CV] .. C=10, penalty=l2, solver=newton-cg, score=0.848, total=   0.2s\n[CV] C=10, penalty=l2, solver=newton-cg ..............................\n[CV] .. C=10, penalty=l2, solver=newton-cg, score=0.835, total=   0.2s\n[CV] C=10, penalty=l2, solver=lbfgs ..................................\n[CV] ...... C=10, penalty=l2, solver=lbfgs, score=0.840, total=   0.3s\n[CV] C=10, penalty=l2, solver=lbfgs ..................................\n[CV] ...... C=10, penalty=l2, solver=lbfgs, score=0.851, total=   0.4s\n[CV] C=10, penalty=l2, solver=lbfgs ..................................\n[CV] ...... C=10, penalty=l2, solver=lbfgs, score=0.884, total=   0.4s\n[CV] C=10, penalty=l2, solver=lbfgs ..................................\n[CV] ...... C=10, penalty=l2, solver=lbfgs, score=0.850, total=   0.4s\n[CV] C=10, penalty=l2, solver=lbfgs ..................................\n[CV] ...... C=10, penalty=l2, solver=lbfgs, score=0.835, total=   0.4s\n[CV] C=10, penalty=l2, solver=sag ....................................\n[CV] ........ C=10, penalty=l2, solver=sag, score=0.861, total=   0.2s\n[CV] C=10, penalty=l2, solver=sag ....................................\n[CV] ........ C=10, penalty=l2, solver=sag, score=0.856, total=   0.2s\n[CV] C=10, penalty=l2, solver=sag ....................................\n[CV] ........ C=10, penalty=l2, solver=sag, score=0.841, total=   0.2s\n[CV] C=10, penalty=l2, solver=sag ....................................\n[CV] ........ C=10, penalty=l2, solver=sag, score=0.868, total=   0.2s\n[CV] C=10, penalty=l2, solver=sag ....................................\n[CV] ........ C=10, penalty=l2, solver=sag, score=0.780, total=   0.2s\n[CV] C=10, penalty=l2, solver=saga ...................................\n[CV] ....... C=10, penalty=l2, solver=saga, score=0.840, total=   0.2s\n[CV] C=10, penalty=l2, solver=saga ...................................\n[CV] ....... C=10, penalty=l2, solver=saga, score=0.843, total=   0.2s\n[CV] C=10, penalty=l2, solver=saga ...................................\n[CV] ....... C=10, penalty=l2, solver=saga, score=0.838, total=   0.2s\n[CV] C=10, penalty=l2, solver=saga ...................................\n[CV] ....... C=10, penalty=l2, solver=saga, score=0.847, total=   0.2s\n[CV] C=10, penalty=l2, solver=saga ...................................\n[CV] ....... C=10, penalty=l2, solver=saga, score=0.791, total=   0.2s\n[CV] C=1.0, penalty=l2, solver=newton-cg .............................\n[CV] . C=1.0, penalty=l2, solver=newton-cg, score=0.848, total=   0.2s\n[CV] C=1.0, penalty=l2, solver=newton-cg .............................\n[CV] . C=1.0, penalty=l2, solver=newton-cg, score=0.859, total=   0.2s\n[CV] C=1.0, penalty=l2, solver=newton-cg .............................\n[CV] . C=1.0, penalty=l2, solver=newton-cg, score=0.884, total=   0.2s\n[CV] C=1.0, penalty=l2, solver=newton-cg .............................\n[CV] . C=1.0, penalty=l2, solver=newton-cg, score=0.864, total=   0.2s\n[CV] C=1.0, penalty=l2, solver=newton-cg .............................\n[CV] . C=1.0, penalty=l2, solver=newton-cg, score=0.845, total=   0.2s\n[CV] C=1.0, penalty=l2, solver=lbfgs .................................\n[CV] ..... C=1.0, penalty=l2, solver=lbfgs, score=0.848, total=   0.4s\n[CV] C=1.0, penalty=l2, solver=lbfgs .................................\n[CV] ..... C=1.0, penalty=l2, solver=lbfgs, score=0.859, total=   0.4s\n[CV] C=1.0, penalty=l2, solver=lbfgs .................................\n[CV] ..... C=1.0, penalty=l2, solver=lbfgs, score=0.884, total=   0.4s\n[CV] C=1.0, penalty=l2, solver=lbfgs .................................\n[CV] ..... C=1.0, penalty=l2, solver=lbfgs, score=0.864, total=   0.4s\n[CV] C=1.0, penalty=l2, solver=lbfgs .................................\n[CV] ..... C=1.0, penalty=l2, solver=lbfgs, score=0.835, total=   0.5s\n[CV] C=1.0, penalty=l2, solver=sag ...................................\n[CV] ....... C=1.0, penalty=l2, solver=sag, score=0.858, total=   0.2s\n[CV] C=1.0, penalty=l2, solver=sag ...................................\n[CV] ....... C=1.0, penalty=l2, solver=sag, score=0.854, total=   0.1s\n[CV] C=1.0, penalty=l2, solver=sag ...................................\n[CV] ....... C=1.0, penalty=l2, solver=sag, score=0.841, total=   0.1s\n[CV] C=1.0, penalty=l2, solver=sag ...................................\n[CV] ....... C=1.0, penalty=l2, solver=sag, score=0.868, total=   0.1s\n[CV] C=1.0, penalty=l2, solver=sag ...................................\n[CV] ....... C=1.0, penalty=l2, solver=sag, score=0.780, total=   0.2s\n[CV] C=1.0, penalty=l2, solver=saga ..................................\n[CV] ...... C=1.0, penalty=l2, solver=saga, score=0.843, total=   0.2s\n[CV] C=1.0, penalty=l2, solver=saga ..................................\n[CV] ...... C=1.0, penalty=l2, solver=saga, score=0.843, total=   0.2s\n[CV] C=1.0, penalty=l2, solver=saga ..................................\n[CV] ...... C=1.0, penalty=l2, solver=saga, score=0.838, total=   0.2s\n[CV] C=1.0, penalty=l2, solver=saga ..................................\n[CV] ...... C=1.0, penalty=l2, solver=saga, score=0.847, total=   0.2s\n[CV] C=1.0, penalty=l2, solver=saga ..................................\n[CV] ...... C=1.0, penalty=l2, solver=saga, score=0.791, total=   0.2s\n[CV] C=0.1, penalty=l2, solver=newton-cg .............................\n[CV] . C=0.1, penalty=l2, solver=newton-cg, score=0.840, total=   0.2s\n[CV] C=0.1, penalty=l2, solver=newton-cg .............................\n[CV] . C=0.1, penalty=l2, solver=newton-cg, score=0.849, total=   0.2s\n[CV] C=0.1, penalty=l2, solver=newton-cg .............................\n[CV] . C=0.1, penalty=l2, solver=newton-cg, score=0.853, total=   0.2s\n[CV] C=0.1, penalty=l2, solver=newton-cg .............................\n[CV] . C=0.1, penalty=l2, solver=newton-cg, score=0.835, total=   0.2s\n[CV] C=0.1, penalty=l2, solver=newton-cg .............................\n[CV] . C=0.1, penalty=l2, solver=newton-cg, score=0.820, total=   0.2s\n[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n[CV] ..... C=0.1, penalty=l2, solver=lbfgs, score=0.840, total=   0.3s\n[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n[CV] ..... C=0.1, penalty=l2, solver=lbfgs, score=0.849, total=   0.3s\n[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n","name":"stdout"},{"output_type":"stream","text":"[CV] ..... C=0.1, penalty=l2, solver=lbfgs, score=0.853, total=   0.3s\n[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n[CV] ..... C=0.1, penalty=l2, solver=lbfgs, score=0.835, total=   0.3s\n[CV] C=0.1, penalty=l2, solver=lbfgs .................................\n[CV] ..... C=0.1, penalty=l2, solver=lbfgs, score=0.820, total=   0.3s\n[CV] C=0.1, penalty=l2, solver=sag ...................................\n[CV] ....... C=0.1, penalty=l2, solver=sag, score=0.858, total=   0.2s\n[CV] C=0.1, penalty=l2, solver=sag ...................................\n[CV] ....... C=0.1, penalty=l2, solver=sag, score=0.854, total=   0.2s\n[CV] C=0.1, penalty=l2, solver=sag ...................................\n[CV] ....... C=0.1, penalty=l2, solver=sag, score=0.841, total=   0.1s\n[CV] C=0.1, penalty=l2, solver=sag ...................................\n[CV] ....... C=0.1, penalty=l2, solver=sag, score=0.868, total=   0.1s\n[CV] C=0.1, penalty=l2, solver=sag ...................................\n[CV] ....... C=0.1, penalty=l2, solver=sag, score=0.780, total=   0.2s\n[CV] C=0.1, penalty=l2, solver=saga ..................................\n[CV] ...... C=0.1, penalty=l2, solver=saga, score=0.843, total=   0.2s\n[CV] C=0.1, penalty=l2, solver=saga ..................................\n[CV] ...... C=0.1, penalty=l2, solver=saga, score=0.843, total=   0.2s\n[CV] C=0.1, penalty=l2, solver=saga ..................................\n[CV] ...... C=0.1, penalty=l2, solver=saga, score=0.838, total=   0.2s\n[CV] C=0.1, penalty=l2, solver=saga ..................................\n[CV] ...... C=0.1, penalty=l2, solver=saga, score=0.847, total=   0.2s\n[CV] C=0.1, penalty=l2, solver=saga ..................................\n[CV] ...... C=0.1, penalty=l2, solver=saga, score=0.791, total=   0.2s\n[CV] C=0.01, penalty=l2, solver=newton-cg ............................\n[CV]  C=0.01, penalty=l2, solver=newton-cg, score=0.762, total=   0.1s\n[CV] C=0.01, penalty=l2, solver=newton-cg ............................\n[CV]  C=0.01, penalty=l2, solver=newton-cg, score=0.779, total=   0.2s\n[CV] C=0.01, penalty=l2, solver=newton-cg ............................\n[CV]  C=0.01, penalty=l2, solver=newton-cg, score=0.814, total=   0.2s\n[CV] C=0.01, penalty=l2, solver=newton-cg ............................\n[CV]  C=0.01, penalty=l2, solver=newton-cg, score=0.768, total=   0.2s\n[CV] C=0.01, penalty=l2, solver=newton-cg ............................\n[CV]  C=0.01, penalty=l2, solver=newton-cg, score=0.747, total=   0.1s\n[CV] C=0.01, penalty=l2, solver=lbfgs ................................\n[CV] .... C=0.01, penalty=l2, solver=lbfgs, score=0.762, total=   0.2s\n[CV] C=0.01, penalty=l2, solver=lbfgs ................................\n[CV] .... C=0.01, penalty=l2, solver=lbfgs, score=0.779, total=   0.2s\n[CV] C=0.01, penalty=l2, solver=lbfgs ................................\n[CV] .... C=0.01, penalty=l2, solver=lbfgs, score=0.814, total=   0.2s\n[CV] C=0.01, penalty=l2, solver=lbfgs ................................\n[CV] .... C=0.01, penalty=l2, solver=lbfgs, score=0.768, total=   0.2s\n[CV] C=0.01, penalty=l2, solver=lbfgs ................................\n[CV] .... C=0.01, penalty=l2, solver=lbfgs, score=0.747, total=   0.2s\n[CV] C=0.01, penalty=l2, solver=sag ..................................\n[CV] ...... C=0.01, penalty=l2, solver=sag, score=0.851, total=   0.2s\n[CV] C=0.01, penalty=l2, solver=sag ..................................\n[CV] ...... C=0.01, penalty=l2, solver=sag, score=0.851, total=   0.1s\n[CV] C=0.01, penalty=l2, solver=sag ..................................\n[CV] ...... C=0.01, penalty=l2, solver=sag, score=0.841, total=   0.1s\n[CV] C=0.01, penalty=l2, solver=sag ..................................\n[CV] ...... C=0.01, penalty=l2, solver=sag, score=0.860, total=   0.1s\n[CV] C=0.01, penalty=l2, solver=sag ..................................\n[CV] ...... C=0.01, penalty=l2, solver=sag, score=0.780, total=   0.1s\n[CV] C=0.01, penalty=l2, solver=saga .................................\n[CV] ..... C=0.01, penalty=l2, solver=saga, score=0.843, total=   0.2s\n[CV] C=0.01, penalty=l2, solver=saga .................................\n[CV] ..... C=0.01, penalty=l2, solver=saga, score=0.843, total=   0.2s\n[CV] C=0.01, penalty=l2, solver=saga .................................\n[CV] ..... C=0.01, penalty=l2, solver=saga, score=0.835, total=   0.2s\n[CV] C=0.01, penalty=l2, solver=saga .................................\n[CV] ..... C=0.01, penalty=l2, solver=saga, score=0.847, total=   0.2s\n[CV] C=0.01, penalty=l2, solver=saga .................................\n[CV] ..... C=0.01, penalty=l2, solver=saga, score=0.791, total=   0.2s\n[CV] C=0.001, penalty=l2, solver=newton-cg ...........................\n[CV]  C=0.001, penalty=l2, solver=newton-cg, score=0.671, total=   0.1s\n[CV] C=0.001, penalty=l2, solver=newton-cg ...........................\n[CV]  C=0.001, penalty=l2, solver=newton-cg, score=0.724, total=   0.1s\n[CV] C=0.001, penalty=l2, solver=newton-cg ...........................\n[CV]  C=0.001, penalty=l2, solver=newton-cg, score=0.713, total=   0.1s\n[CV] C=0.001, penalty=l2, solver=newton-cg ...........................\n[CV]  C=0.001, penalty=l2, solver=newton-cg, score=0.661, total=   0.1s\n[CV] C=0.001, penalty=l2, solver=newton-cg ...........................\n[CV]  C=0.001, penalty=l2, solver=newton-cg, score=0.624, total=   0.1s\n[CV] C=0.001, penalty=l2, solver=lbfgs ...............................\n[CV] ... C=0.001, penalty=l2, solver=lbfgs, score=0.671, total=   0.1s\n[CV] C=0.001, penalty=l2, solver=lbfgs ...............................\n[CV] ... C=0.001, penalty=l2, solver=lbfgs, score=0.724, total=   0.1s\n[CV] C=0.001, penalty=l2, solver=lbfgs ...............................\n[CV] ... C=0.001, penalty=l2, solver=lbfgs, score=0.713, total=   0.1s\n[CV] C=0.001, penalty=l2, solver=lbfgs ...............................\n[CV] ... C=0.001, penalty=l2, solver=lbfgs, score=0.661, total=   0.1s\n[CV] C=0.001, penalty=l2, solver=lbfgs ...............................\n[CV] ... C=0.001, penalty=l2, solver=lbfgs, score=0.624, total=   0.1s\n[CV] C=0.001, penalty=l2, solver=sag .................................\n[CV] ..... C=0.001, penalty=l2, solver=sag, score=0.832, total=   0.2s\n[CV] C=0.001, penalty=l2, solver=sag .................................\n[CV] ..... C=0.001, penalty=l2, solver=sag, score=0.843, total=   0.2s\n[CV] C=0.001, penalty=l2, solver=sag .................................\n[CV] ..... C=0.001, penalty=l2, solver=sag, score=0.845, total=   0.1s\n[CV] C=0.001, penalty=l2, solver=sag .................................\n[CV] ..... C=0.001, penalty=l2, solver=sag, score=0.839, total=   0.1s\n[CV] C=0.001, penalty=l2, solver=sag .................................\n[CV] ..... C=0.001, penalty=l2, solver=sag, score=0.780, total=   0.1s\n[CV] C=0.001, penalty=l2, solver=saga ................................\n[CV] .... C=0.001, penalty=l2, solver=saga, score=0.835, total=   0.2s\n[CV] C=0.001, penalty=l2, solver=saga ................................\n[CV] .... C=0.001, penalty=l2, solver=saga, score=0.843, total=   0.2s\n[CV] C=0.001, penalty=l2, solver=saga ................................\n[CV] .... C=0.001, penalty=l2, solver=saga, score=0.845, total=   0.2s\n[CV] C=0.001, penalty=l2, solver=saga ................................\n[CV] .... C=0.001, penalty=l2, solver=saga, score=0.839, total=   0.2s\n[CV] C=0.001, penalty=l2, solver=saga ................................\n[CV] .... C=0.001, penalty=l2, solver=saga, score=0.780, total=   0.2s\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   24.8s finished\n","name":"stderr"},{"output_type":"stream","text":"Best score: 0.8600706818721786\nBest parameters set:\n\tC: 1.0\n\tpenalty: l2\n\tsolver: newton-cg\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Now let's take penalty l1 and solvers ‘liblinear’ and ‘saga’ \nas they handle l1 penalty. \nand check if they improves the results"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import linear_model\nfrom sklearn import metrics\nfrom sklearn import model_selection\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import make_scorer\n\nif __name__ ==\"__main__\":\n    \n    \n    #randomize the data\n    df_hpo = df_hpo.sample(frac = 1).reset_index(drop =True)\n    \n    #initialize the count vector tokenizer with NLTK word tokenize\n    count_vec = CountVectorizer(tokenizer = word_tokenize, token_pattern = None)\n    \n    #fit the count vector\n    count_vec.fit(df_hpo.TRANS_CONV_TEXT)\n    pickle.dump(count_vec, open(\"count_vectorizer.pickle\", \"wb\")) \n    \n    #transform the training and validation data reviews\n    X = count_vec.transform(df_hpo.TRANS_CONV_TEXT)\n    y = df_hpo.Patient_Tag.values\n    \n    classifier = linear_model.LogisticRegression()\n    param_grid = {\n                    \"solver\": ['saga','liblinear'],\n                    \"penalty\": ['l1'],\n                    \"C\": [100, 10, 1.0, 0.1, 0.01, 0.001]\n                }\n    roc_auc_weighted = metrics.make_scorer(metrics.roc_auc_score, average='weighted')\n    model = model_selection.GridSearchCV(\n                        estimator=classifier,\n                        param_grid=param_grid,\n                        scoring=roc_auc_weighted,\n                        verbose=10,\n                        n_jobs=1,\n                        cv=5\n                        ) \n  \n    model.fit(X, y)\n    print(f\"Best score: {model.best_score_}\")\n    print(\"Best parameters set:\")\n    best_parameters = model.best_estimator_.get_params()\n    for param_name in sorted(param_grid.keys()):\n        print(f\"\\t{param_name}: {best_parameters[param_name]}\")\n    \n","execution_count":43,"outputs":[{"output_type":"stream","text":"Fitting 5 folds for each of 12 candidates, totalling 60 fits\n[CV] C=100, penalty=l1, solver=saga ..................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","name":"stderr"},{"output_type":"stream","text":"[CV] ...... C=100, penalty=l1, solver=saga, score=0.718, total=   6.0s\n[CV] C=100, penalty=l1, solver=saga ..................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.0s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ...... C=100, penalty=l1, solver=saga, score=0.869, total=   6.2s\n[CV] C=100, penalty=l1, solver=saga ..................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   12.2s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ...... C=100, penalty=l1, solver=saga, score=0.825, total=   6.2s\n[CV] C=100, penalty=l1, solver=saga ..................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   18.4s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ...... C=100, penalty=l1, solver=saga, score=0.885, total=   6.6s\n[CV] C=100, penalty=l1, solver=saga ..................................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   25.0s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] ...... C=100, penalty=l1, solver=saga, score=0.847, total=   6.5s\n[CV] C=100, penalty=l1, solver=liblinear .............................\n[CV] . C=100, penalty=l1, solver=liblinear, score=0.871, total=   0.1s\n[CV] C=100, penalty=l1, solver=liblinear .............................\n[CV] . C=100, penalty=l1, solver=liblinear, score=0.879, total=   0.1s\n[CV] C=100, penalty=l1, solver=liblinear .............................\n[CV] . C=100, penalty=l1, solver=liblinear, score=0.882, total=   0.0s\n[CV] C=100, penalty=l1, solver=liblinear .............................\n[CV] . C=100, penalty=l1, solver=liblinear, score=0.804, total=   0.0s\n[CV] C=100, penalty=l1, solver=liblinear .............................\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   31.5s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   31.5s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   31.6s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   31.6s remaining:    0.0s\n[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   31.7s remaining:    0.0s\n","name":"stderr"},{"output_type":"stream","text":"[CV] . C=100, penalty=l1, solver=liblinear, score=0.897, total=   0.0s\n[CV] C=10, penalty=l1, solver=saga ...................................\n[CV] ....... C=10, penalty=l1, solver=saga, score=0.718, total=   4.5s\n[CV] C=10, penalty=l1, solver=saga ...................................\n[CV] ....... C=10, penalty=l1, solver=saga, score=0.879, total=   4.7s\n[CV] C=10, penalty=l1, solver=saga ...................................\n[CV] ....... C=10, penalty=l1, solver=saga, score=0.825, total=   4.7s\n[CV] C=10, penalty=l1, solver=saga ...................................\n[CV] ....... C=10, penalty=l1, solver=saga, score=0.885, total=   5.0s\n[CV] C=10, penalty=l1, solver=saga ...................................\n[CV] ....... C=10, penalty=l1, solver=saga, score=0.847, total=   4.8s\n[CV] C=10, penalty=l1, solver=liblinear ..............................\n[CV] .. C=10, penalty=l1, solver=liblinear, score=0.830, total=   0.1s\n[CV] C=10, penalty=l1, solver=liblinear ..............................\n[CV] .. C=10, penalty=l1, solver=liblinear, score=0.884, total=   0.0s\n[CV] C=10, penalty=l1, solver=liblinear ..............................\n[CV] .. C=10, penalty=l1, solver=liblinear, score=0.824, total=   0.0s\n[CV] C=10, penalty=l1, solver=liblinear ..............................\n[CV] .. C=10, penalty=l1, solver=liblinear, score=0.838, total=   0.0s\n[CV] C=10, penalty=l1, solver=liblinear ..............................\n[CV] .. C=10, penalty=l1, solver=liblinear, score=0.873, total=   0.0s\n[CV] C=1.0, penalty=l1, solver=saga ..................................\n[CV] ...... C=1.0, penalty=l1, solver=saga, score=0.718, total=   1.3s\n[CV] C=1.0, penalty=l1, solver=saga ..................................\n[CV] ...... C=1.0, penalty=l1, solver=saga, score=0.869, total=   1.4s\n[CV] C=1.0, penalty=l1, solver=saga ..................................\n[CV] ...... C=1.0, penalty=l1, solver=saga, score=0.825, total=   1.3s\n[CV] C=1.0, penalty=l1, solver=saga ..................................\n[CV] ...... C=1.0, penalty=l1, solver=saga, score=0.885, total=   1.5s\n[CV] C=1.0, penalty=l1, solver=saga ..................................\n[CV] ...... C=1.0, penalty=l1, solver=saga, score=0.836, total=   1.4s\n[CV] C=1.0, penalty=l1, solver=liblinear .............................\n[CV] . C=1.0, penalty=l1, solver=liblinear, score=0.814, total=   0.0s\n[CV] C=1.0, penalty=l1, solver=liblinear .............................\n[CV] . C=1.0, penalty=l1, solver=liblinear, score=0.877, total=   0.0s\n[CV] C=1.0, penalty=l1, solver=liblinear .............................\n[CV] . C=1.0, penalty=l1, solver=liblinear, score=0.837, total=   0.0s\n[CV] C=1.0, penalty=l1, solver=liblinear .............................\n[CV] . C=1.0, penalty=l1, solver=liblinear, score=0.846, total=   0.0s\n[CV] C=1.0, penalty=l1, solver=liblinear .............................\n[CV] . C=1.0, penalty=l1, solver=liblinear, score=0.894, total=   0.0s\n[CV] C=0.1, penalty=l1, solver=saga ..................................\n[CV] ...... C=0.1, penalty=l1, solver=saga, score=0.715, total=   0.3s\n[CV] C=0.1, penalty=l1, solver=saga ..................................\n[CV] ...... C=0.1, penalty=l1, solver=saga, score=0.861, total=   0.3s\n[CV] C=0.1, penalty=l1, solver=saga ..................................\n[CV] ...... C=0.1, penalty=l1, solver=saga, score=0.804, total=   0.3s\n[CV] C=0.1, penalty=l1, solver=saga ..................................\n[CV] ...... C=0.1, penalty=l1, solver=saga, score=0.885, total=   0.3s\n[CV] C=0.1, penalty=l1, solver=saga ..................................\n[CV] ...... C=0.1, penalty=l1, solver=saga, score=0.821, total=   0.3s\n[CV] C=0.1, penalty=l1, solver=liblinear .............................\n[CV] . C=0.1, penalty=l1, solver=liblinear, score=0.734, total=   0.0s\n[CV] C=0.1, penalty=l1, solver=liblinear .............................\n[CV] . C=0.1, penalty=l1, solver=liblinear, score=0.786, total=   0.0s\n[CV] C=0.1, penalty=l1, solver=liblinear .............................\n[CV] . C=0.1, penalty=l1, solver=liblinear, score=0.783, total=   0.0s\n[CV] C=0.1, penalty=l1, solver=liblinear .............................\n[CV] . C=0.1, penalty=l1, solver=liblinear, score=0.815, total=   0.0s\n[CV] C=0.1, penalty=l1, solver=liblinear .............................\n[CV] . C=0.1, penalty=l1, solver=liblinear, score=0.772, total=   0.0s\n[CV] C=0.01, penalty=l1, solver=saga .................................\n[CV] ..... C=0.01, penalty=l1, solver=saga, score=0.738, total=   0.2s\n[CV] C=0.01, penalty=l1, solver=saga .................................\n[CV] ..... C=0.01, penalty=l1, solver=saga, score=0.882, total=   0.2s\n[CV] C=0.01, penalty=l1, solver=saga .................................\n[CV] ..... C=0.01, penalty=l1, solver=saga, score=0.790, total=   0.2s\n[CV] C=0.01, penalty=l1, solver=saga .................................\n[CV] ..... C=0.01, penalty=l1, solver=saga, score=0.903, total=   0.2s\n[CV] C=0.01, penalty=l1, solver=saga .................................\n[CV] ..... C=0.01, penalty=l1, solver=saga, score=0.836, total=   0.2s\n[CV] C=0.01, penalty=l1, solver=liblinear ............................\n[CV]  C=0.01, penalty=l1, solver=liblinear, score=0.738, total=   0.0s\n[CV] C=0.01, penalty=l1, solver=liblinear ............................\n[CV]  C=0.01, penalty=l1, solver=liblinear, score=0.864, total=   0.0s\n[CV] C=0.01, penalty=l1, solver=liblinear ............................\n[CV]  C=0.01, penalty=l1, solver=liblinear, score=0.793, total=   0.0s\n[CV] C=0.01, penalty=l1, solver=liblinear ............................\n[CV]  C=0.01, penalty=l1, solver=liblinear, score=0.895, total=   0.0s\n[CV] C=0.01, penalty=l1, solver=liblinear ............................\n[CV]  C=0.01, penalty=l1, solver=liblinear, score=0.810, total=   0.0s\n[CV] C=0.001, penalty=l1, solver=saga ................................\n[CV] .... C=0.001, penalty=l1, solver=saga, score=0.500, total=   0.0s\n[CV] C=0.001, penalty=l1, solver=saga ................................\n[CV] .... C=0.001, penalty=l1, solver=saga, score=0.500, total=   0.1s\n[CV] C=0.001, penalty=l1, solver=saga ................................\n[CV] .... C=0.001, penalty=l1, solver=saga, score=0.562, total=   0.1s\n[CV] C=0.001, penalty=l1, solver=saga ................................\n[CV] .... C=0.001, penalty=l1, solver=saga, score=0.500, total=   0.0s\n[CV] C=0.001, penalty=l1, solver=saga ................................\n[CV] .... C=0.001, penalty=l1, solver=saga, score=0.500, total=   0.1s\n[CV] C=0.001, penalty=l1, solver=liblinear ...........................\n[CV]  C=0.001, penalty=l1, solver=liblinear, score=0.500, total=   0.0s\n[CV] C=0.001, penalty=l1, solver=liblinear ...........................\n[CV]  C=0.001, penalty=l1, solver=liblinear, score=0.500, total=   0.0s\n[CV] C=0.001, penalty=l1, solver=liblinear ...........................\n[CV]  C=0.001, penalty=l1, solver=liblinear, score=0.565, total=   0.0s\n[CV] C=0.001, penalty=l1, solver=liblinear ...........................\n[CV]  C=0.001, penalty=l1, solver=liblinear, score=0.500, total=   0.0s\n[CV] C=0.001, penalty=l1, solver=liblinear ...........................\n[CV]  C=0.001, penalty=l1, solver=liblinear, score=0.500, total=   0.0s\nBest score: 0.8665567830838679\nBest parameters set:\n\tC: 100\n\tpenalty: l1\n\tsolver: liblinear\n","name":"stdout"},{"output_type":"stream","text":"[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  1.1min finished\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"With l1 penalty, c= 100 and liblinear solver we get 86.65 rocauc our best score. Which is 0.65 higher than l1 penalty. So we will impliment the best parameters and check the results."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"df = train_df.copy()\ndf_test = test_df.copy()\n\nfrom sklearn import linear_model\nfrom sklearn import metrics\nfrom sklearn import model_selection\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\n\nif __name__ ==\"__main__\":\n    #create a new column with and fill it with -1\n    df['kfold'] = -1\n    #randomize the data\n    df = df.sample(frac = 1).reset_index(drop =True)\n    y = df.Patient_Tag.values\n    #initiate model selection class from stratified kfold module\n    kf = model_selection.StratifiedKFold(n_splits = 5)\n    \n    # fill the new k fold column\n    for f,(t_,v_) in enumerate(kf.split(X =df,y = y)):\n        df.loc[v_,'kfold'] = f\n\n    #go over the folds created\n    for fold_ in range(5):\n        \n        #creating temporary dataframes for train and test\n        train_data = df[df.kfold != fold_].reset_index(drop = True)\n        test_data = df[df.kfold == fold_].reset_index(drop = True)\n\n        #initialize the count vector tokenizer with NLTK word tokenize\n        count_vec = CountVectorizer(tokenizer = word_tokenize, token_pattern = None)\n        \n        #fit the count vector\n        count_vec.fit(train_data.TRANS_CONV_TEXT)\n        pickle.dump(count_vec, open(\"count_vectorizer.pickle\", \"wb\")) \n        \n        #transform the training and validation data reviews\n        xtrain = count_vec.transform(train_data.TRANS_CONV_TEXT)\n        xtest = count_vec.transform(test_data.TRANS_CONV_TEXT)\n\n\n        model = linear_model.LogisticRegression(C = 100, penalty = 'l1',solver = 'liblinear')\n        model.fit(xtrain,train_data.Patient_Tag)\n        \n        preds = model.predict(xtest)\n        roc_auc_score = metrics.roc_auc_score(test_data.Patient_Tag,preds)\n        \n        print(f'fold : {fold_}')\n        print(f'roc_auc = {roc_auc_score}')\n        print(classification_report(test_data.Patient_Tag,preds))\n        print(f\"Accuracy Score = {accuracy_score(test_data.Patient_Tag,preds)}\")\n              \n        print('<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>>>')\n","execution_count":40,"outputs":[{"output_type":"stream","text":"fold : 0\nroc_auc = 0.8301630434782609\n              precision    recall  f1-score   support\n\n           0       0.92      0.97      0.95       184\n           1       0.87      0.69      0.77        48\n\n    accuracy                           0.91       232\n   macro avg       0.90      0.83      0.86       232\nweighted avg       0.91      0.91      0.91       232\n\nAccuracy Score = 0.9137931034482759\n<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>>>\nfold : 1\nroc_auc = 0.8350409836065574\n              precision    recall  f1-score   support\n\n           0       0.93      0.96      0.94       183\n           1       0.83      0.71      0.76        48\n\n    accuracy                           0.91       231\n   macro avg       0.88      0.84      0.85       231\nweighted avg       0.91      0.91      0.91       231\n\nAccuracy Score = 0.9090909090909091\n<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>>>\nfold : 2\nroc_auc = 0.8536543715846994\n              precision    recall  f1-score   support\n\n           0       0.93      0.98      0.95       183\n           1       0.90      0.73      0.80        48\n\n    accuracy                           0.93       231\n   macro avg       0.91      0.85      0.88       231\nweighted avg       0.93      0.93      0.92       231\n\nAccuracy Score = 0.9264069264069265\n<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>>>\nfold : 3\nroc_auc = 0.8531420765027322\n              precision    recall  f1-score   support\n\n           0       0.94      0.96      0.95       183\n           1       0.82      0.75      0.78        48\n\n    accuracy                           0.91       231\n   macro avg       0.88      0.85      0.86       231\nweighted avg       0.91      0.91      0.91       231\n\nAccuracy Score = 0.9134199134199135\n<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>>>\nfold : 4\nroc_auc = 0.8372609289617485\n              precision    recall  f1-score   support\n\n           0       0.93      0.95      0.94       183\n           1       0.78      0.73      0.75        48\n\n    accuracy                           0.90       231\n   macro avg       0.85      0.84      0.85       231\nweighted avg       0.90      0.90      0.90       231\n\nAccuracy Score = 0.9004329004329005\n<<<<<<<<<<<<<<<<<<<<<<>>>>>>>>>>>>>>>>>>>\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"It seems the default parameters are the best for our model. \nWe will take the submission file. "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = test_df.copy()","execution_count":41,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"count_vec = pickle.load(open(\"./count_vectorizer.pickle\", 'rb'))\ntest_features = count_vec.transform(df_test.TRANS_CONV_TEXT)\ntest_preds = model.predict(test_features)\nsubmission_logistic_hpo = pd.read_csv('../input/zsdataset/test.csv',encoding = 'ISO-8859-1')\nsubmission = pd.DataFrame()\nsubmission['Index'] = submission_logistic_hpo['Index']\nsubmission['Patient_Tag'] = test_preds\nsubmission.to_csv('submission_logistic_bow_hpo.csv',index = False)","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# References \n* sklearn website \n* https://www.amazon.de/Approaching-Almost-Machine-Learning-Problem/dp/8269211508/ref=asc_df_8269211508/?tag=googshopde21&linkCode=df0&hvadid=447482931749&hvpos=&hvnetw=g&hvrand=1474972248643818998&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=9042923&hvtargid=pla-922436928846&psc=1&th=1&psc=1"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}