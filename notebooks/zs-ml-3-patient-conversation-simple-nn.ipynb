{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install tldextract","execution_count":98,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: tldextract in /opt/conda/lib/python3.7/site-packages (3.1.0)\nRequirement already satisfied: requests>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from tldextract) (2.25.1)\nRequirement already satisfied: idna in /opt/conda/lib/python3.7/site-packages (from tldextract) (2.10)\nRequirement already satisfied: requests-file>=1.4 in /opt/conda/lib/python3.7/site-packages (from tldextract) (1.5.1)\nRequirement already satisfied: filelock>=3.0.8 in /opt/conda/lib/python3.7/site-packages (from tldextract) (3.0.12)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.1.0->tldextract) (1.26.2)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.1.0->tldextract) (2020.12.5)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.1.0->tldextract) (3.0.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from requests-file>=1.4->tldextract) (1.15.0)\n\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tldextract import extract\nimport re,sys,os\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":99,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#nltk libraries\nimport nltk\nfrom nltk.stem import WordNetLemmatizer,PorterStemmer\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nnltk.download('stopwords')\nstop=set(stopwords.words('english'))\nfrom nltk.stem.snowball import SnowballStemmer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt","execution_count":100,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","name":"stdout"}]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#import libraries\nimport keras\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense\nfrom keras.models import Model\nfrom keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import sequence\nfrom keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.preprocessing.sequence import pad_sequences","execution_count":101,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/zsdataset/train.csv',encoding= 'ISO-8859-1')\ntest_df = pd.read_csv('../input/zsdataset/test.csv',encoding= 'ISO-8859-1')\n\n#extracts the url from the link, we will extract hostname only\ndef extract_url(x):\n    tsd, td, tsu = extract(x) # prints abc, hostname, com\n    return td\n\ndef classes_def(x):\n    if x ==  \"FACEBOOK\":\n        return \"Facebook\"\n    elif x == 'FORUMS':\n        return 'Forums'\n    elif x == 'BLOG':\n        return 'Blog'\n    elif x == 'YOUTUBE':\n        return 'Youtube'\n    else:\n        return 'Facebook'\n\ndef clean_text(x):\n    normalizedsentense = x.lower()\n    text = re.sub(r\"[^a-z']+\", ' ', normalizedsentense)\n    return text\n\n\nstemmer = SnowballStemmer('english')\ndef stemming(sentence):\n    word_list = nltk.word_tokenize(sentence)\n    stemmed_output = ' '.join([stemmer.stem(w) for w in word_list])\n    return stemmed_output\n\ntrain_df['Source']=train_df['Source'].apply(lambda x:classes_def(x))\ntest_df['Source']=test_df['Source'].apply(lambda x:classes_def(x))\ntrain_df[\"Host\"].fillna(train_df[\"Link\"], inplace=True)\ntest_df[\"Host\"].fillna(test_df[\"Link\"], inplace=True)\ntrain_df['Host']=train_df['Host'].apply(lambda x:extract_url(x))\ntest_df['Host']=test_df['Host'].apply(lambda x:extract_url(x))\ntrain_df.loc[train_df.Host == '' , 'Host'] = 'youtube'\n\ntrain_df = train_df.drop(['Link','time(GMT)','Title'],axis= 1)\ntest_df = test_df.drop(['Link','time(GMT)','Title'],axis= 1)\n\ntrain_df['Date(ET)'] = pd.to_datetime(train_df['Date(ET)'],errors='coerce').dt.date\ntest_df['Date(ET)'] = pd.to_datetime(test_df['Date(ET)'],errors='coerce').dt.date\n\ntrain_df['Time(ET)'] = pd.to_datetime(train_df['Time(ET)'],errors='coerce').dt.time\ntest_df['Time(ET)'] = pd.to_datetime(test_df['Time(ET)'],errors='coerce').dt.time\n\ntest_df.drop(columns = ['Index','Unnamed: 9'],inplace = True)\n\ntrain_df = train_df[train_df['TRANS_CONV_TEXT'].notna()]\n\ntrain_df['TRANS_CONV_TEXT']=train_df['TRANS_CONV_TEXT'].apply(lambda x:clean_text(x))\ntest_df['TRANS_CONV_TEXT']=test_df['TRANS_CONV_TEXT'].apply(lambda x:clean_text(x))\n\ntrain_df['TRANS_CONV_TEXT']=train_df['TRANS_CONV_TEXT'].apply(lambda x: stemming(x))\ntest_df['TRANS_CONV_TEXT']=test_df['TRANS_CONV_TEXT'].apply(lambda x: stemming(x))","execution_count":102,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tokenization"},{"metadata":{"trusted":true},"cell_type":"code","source":"VOCAB_SIZE=4500\nMAXLEN=2000\ntokenizer=Tokenizer(VOCAB_SIZE,oov_token='<oov>', filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')  # filtering special characters\ntrain_data = train_df[['TRANS_CONV_TEXT','Patient_Tag']]\ntest_data = test_df[['TRANS_CONV_TEXT']]\ntokenizer.fit_on_texts(train_data.TRANS_CONV_TEXT)\ntokenizer.fit_on_texts(test_data.TRANS_CONV_TEXT)","execution_count":103,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def df_to_padded_sequences(df,tokenizer):\n    sequences=tokenizer.texts_to_sequences(df.TRANS_CONV_TEXT)                                              #text to sequence of integers\n    padded_sequences=pad_sequences(sequences,maxlen=MAXLEN, padding='post', truncating='post')  #padding\n    return padded_sequences\n\nX_train=df_to_padded_sequences(train_df,tokenizer)\ndf_test=df_to_padded_sequences(test_df,tokenizer)","execution_count":104,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test","execution_count":105,"outputs":[{"output_type":"execute_result","execution_count":105,"data":{"text/plain":"array([[1206, 2526,    2, ...,    0,    0,    0],\n       [ 336, 3523,  561, ...,    0,    0,    0],\n       [ 746,  488, 1531, ...,    0,    0,    0],\n       ...,\n       [ 943,    2,  100, ...,    0,    0,    0],\n       [ 229,  552,    8, ...,    0,    0,    0],\n       [1021,    8,  166, ...,    0,    0,    0]], dtype=int32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train_df.Patient_Tag","execution_count":106,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train ,X_test, y_train, y_test = train_test_split(X_train, y_train, test_size = 0.2, random_state = 42)","execution_count":107,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training features shape: ',X_train.shape)\nprint('Validation features shape: ',X_test.shape)\n\nprint('Training labels shape: ', y_train.shape)\nprint('Validation labels shape: ', y_test.shape)","execution_count":108,"outputs":[{"output_type":"stream","text":"Training features shape:  (924, 2000)\nValidation features shape:  (232, 2000)\nTraining labels shape:  (924,)\nValidation labels shape:  (232,)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = keras.Sequential([\n    keras.layers.Embedding(VOCAB_SIZE, 32,input_length=MAXLEN),\n    keras.layers.SpatialDropout1D(0.2),\n    keras.layers.Bidirectional(keras.layers.LSTM(16)),\n    keras.layers.Dense(1, activation=\"sigmoid\")\n])","execution_count":112,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1.summary()","execution_count":113,"outputs":[{"output_type":"stream","text":"Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_5 (Embedding)      (None, 2000, 32)          144000    \n_________________________________________________________________\nspatial_dropout1d_5 (Spatial (None, 2000, 32)          0         \n_________________________________________________________________\nbidirectional_5 (Bidirection (None, 32)                6272      \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 33        \n=================================================================\nTotal params: 150,305\nTrainable params: 150,305\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS=30\n\nearly_stopping = keras.callbacks.EarlyStopping(\n    monitor='val_acc', \n    verbose=1,\n    patience=5,\n    mode='max',\n    restore_best_weights=True)\n\nmodel1.compile(loss=\"binary_crossentropy\",optimizer=keras.optimizers.RMSprop(1e-4), metrics=['accuracy'])\n\nhistory1 = model1.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=EPOCHS, callbacks = [early_stopping])","execution_count":122,"outputs":[{"output_type":"stream","text":"Epoch 1/30\n29/29 [==============================] - 8s 169ms/step - loss: 0.0640 - accuracy: 0.9891 - val_loss: 0.3695 - val_accuracy: 0.8836\nEpoch 2/30\n29/29 [==============================] - 4s 138ms/step - loss: 0.0603 - accuracy: 0.9915 - val_loss: 0.3575 - val_accuracy: 0.8836\nEpoch 3/30\n29/29 [==============================] - 4s 141ms/step - loss: 0.0635 - accuracy: 0.9883 - val_loss: 0.3867 - val_accuracy: 0.8750\nEpoch 4/30\n29/29 [==============================] - 4s 138ms/step - loss: 0.0687 - accuracy: 0.9849 - val_loss: 0.3798 - val_accuracy: 0.8793\nEpoch 5/30\n29/29 [==============================] - 4s 144ms/step - loss: 0.0547 - accuracy: 0.9880 - val_loss: 0.3835 - val_accuracy: 0.8750\nEpoch 6/30\n29/29 [==============================] - 4s 138ms/step - loss: 0.0543 - accuracy: 0.9926 - val_loss: 0.3814 - val_accuracy: 0.8836\nEpoch 7/30\n29/29 [==============================] - 4s 138ms/step - loss: 0.0557 - accuracy: 0.9901 - val_loss: 0.3940 - val_accuracy: 0.8750\nEpoch 8/30\n29/29 [==============================] - 4s 141ms/step - loss: 0.0609 - accuracy: 0.9909 - val_loss: 0.3786 - val_accuracy: 0.8793\nEpoch 9/30\n29/29 [==============================] - 4s 143ms/step - loss: 0.0617 - accuracy: 0.9836 - val_loss: 0.3885 - val_accuracy: 0.8750\nEpoch 10/30\n29/29 [==============================] - 4s 138ms/step - loss: 0.0468 - accuracy: 0.9920 - val_loss: 0.3964 - val_accuracy: 0.8707\nEpoch 11/30\n29/29 [==============================] - 4s 143ms/step - loss: 0.0668 - accuracy: 0.9826 - val_loss: 0.3938 - val_accuracy: 0.8707\nEpoch 12/30\n29/29 [==============================] - 4s 138ms/step - loss: 0.0599 - accuracy: 0.9821 - val_loss: 0.3904 - val_accuracy: 0.8793\nEpoch 13/30\n29/29 [==============================] - 4s 139ms/step - loss: 0.0522 - accuracy: 0.9903 - val_loss: 0.3982 - val_accuracy: 0.8750\nEpoch 14/30\n29/29 [==============================] - 4s 140ms/step - loss: 0.0426 - accuracy: 0.9949 - val_loss: 0.4048 - val_accuracy: 0.8707\nEpoch 15/30\n29/29 [==============================] - 4s 139ms/step - loss: 0.0478 - accuracy: 0.9926 - val_loss: 0.4022 - val_accuracy: 0.8750\nEpoch 16/30\n29/29 [==============================] - 4s 142ms/step - loss: 0.0585 - accuracy: 0.9874 - val_loss: 0.4067 - val_accuracy: 0.8707\nEpoch 17/30\n29/29 [==============================] - 4s 142ms/step - loss: 0.0465 - accuracy: 0.9919 - val_loss: 0.4043 - val_accuracy: 0.8750\nEpoch 18/30\n29/29 [==============================] - 4s 138ms/step - loss: 0.0393 - accuracy: 0.9917 - val_loss: 0.4098 - val_accuracy: 0.8750\nEpoch 19/30\n29/29 [==============================] - 4s 141ms/step - loss: 0.0474 - accuracy: 0.9915 - val_loss: 0.4177 - val_accuracy: 0.8707\nEpoch 20/30\n29/29 [==============================] - 4s 139ms/step - loss: 0.0424 - accuracy: 0.9926 - val_loss: 0.4063 - val_accuracy: 0.8793\nEpoch 21/30\n29/29 [==============================] - 4s 139ms/step - loss: 0.0473 - accuracy: 0.9873 - val_loss: 0.4084 - val_accuracy: 0.8793\nEpoch 22/30\n29/29 [==============================] - 4s 141ms/step - loss: 0.0358 - accuracy: 0.9944 - val_loss: 0.4129 - val_accuracy: 0.8793\nEpoch 23/30\n29/29 [==============================] - 4s 138ms/step - loss: 0.0389 - accuracy: 0.9948 - val_loss: 0.4362 - val_accuracy: 0.8664\nEpoch 24/30\n29/29 [==============================] - 4s 142ms/step - loss: 0.0517 - accuracy: 0.9888 - val_loss: 0.4175 - val_accuracy: 0.8793\nEpoch 25/30\n29/29 [==============================] - 4s 145ms/step - loss: 0.0394 - accuracy: 0.9948 - val_loss: 0.4363 - val_accuracy: 0.8707\nEpoch 26/30\n29/29 [==============================] - 4s 139ms/step - loss: 0.0420 - accuracy: 0.9933 - val_loss: 0.4206 - val_accuracy: 0.8793\nEpoch 27/30\n29/29 [==============================] - 4s 142ms/step - loss: 0.0410 - accuracy: 0.9923 - val_loss: 0.4208 - val_accuracy: 0.8793\nEpoch 28/30\n29/29 [==============================] - 4s 138ms/step - loss: 0.0360 - accuracy: 0.9934 - val_loss: 0.4240 - val_accuracy: 0.8793\nEpoch 29/30\n29/29 [==============================] - 4s 138ms/step - loss: 0.0337 - accuracy: 0.9948 - val_loss: 0.4372 - val_accuracy: 0.8793\nEpoch 30/30\n29/29 [==============================] - 4s 142ms/step - loss: 0.0463 - accuracy: 0.9915 - val_loss: 0.4297 - val_accuracy: 0.8793\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_val=model1.predict(X_test)\nresults_val = [int(i>0.5) for i in results_val]\nprint(f'roc_auc = {metrics.roc_auc_score(y_test,results_val)}')\nprint(classification_report(y_test,results_val))\nprint(f\"Accuracy Score = {accuracy_score(y_test,results_val)}\")","execution_count":125,"outputs":[{"output_type":"stream","text":"roc_auc = 0.7624117213028355\n              precision    recall  f1-score   support\n\n           0       0.88      0.98      0.93       179\n           1       0.88      0.55      0.67        53\n\n    accuracy                           0.88       232\n   macro avg       0.88      0.76      0.80       232\nweighted avg       0.88      0.88      0.87       232\n\nAccuracy Score = 0.8793103448275862\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"The results are not as good as it can be. But we can get a generics idea of LSTM "},{"metadata":{"trusted":true},"cell_type":"code","source":"results_test=model1.predict(df_test)","execution_count":118,"outputs":[{"output_type":"stream","text":"[[0.02114462]\n [0.0543978 ]\n [0.0215206 ]\n [0.86225826]\n [0.01820859]\n [0.0129878 ]\n [0.0292798 ]\n [0.07236271]\n [0.02666892]\n [0.01426792]\n [0.0210984 ]\n [0.01608971]\n [0.9046669 ]\n [0.01750873]\n [0.8435663 ]\n [0.89162296]\n [0.01856   ]\n [0.01767087]\n [0.01872816]\n [0.01635309]\n [0.0786112 ]\n [0.0215809 ]\n [0.02177105]\n [0.75974834]\n [0.01912771]\n [0.01866411]\n [0.01724737]\n [0.02229598]\n [0.07647318]\n [0.02203828]\n [0.017695  ]\n [0.01179892]\n [0.01801868]\n [0.02027011]\n [0.01609847]\n [0.45788285]\n [0.8299889 ]\n [0.02101289]\n [0.01532494]\n [0.01162338]\n [0.02415241]\n [0.04548585]\n [0.02307042]\n [0.0457787 ]\n [0.8651436 ]\n [0.03285392]\n [0.01854251]\n [0.8220957 ]\n [0.01812096]\n [0.01721468]\n [0.02035712]\n [0.01188848]\n [0.03021155]\n [0.01682877]\n [0.18996653]\n [0.7391718 ]\n [0.02320146]\n [0.01392793]\n [0.02206663]\n [0.01779619]\n [0.01663175]\n [0.02217299]\n [0.05568039]\n [0.04332101]\n [0.02057016]\n [0.01965763]\n [0.01441625]\n [0.01868075]\n [0.04995175]\n [0.02114366]\n [0.01792423]\n [0.8808711 ]\n [0.02126343]\n [0.025113  ]\n [0.03004192]\n [0.8502928 ]\n [0.0294328 ]\n [0.85230124]\n [0.02407376]\n [0.0149336 ]\n [0.01951249]\n [0.040079  ]\n [0.01980795]\n [0.01692622]\n [0.0161204 ]\n [0.6089657 ]\n [0.02217569]\n [0.02894392]\n [0.01764917]\n [0.87827754]\n [0.02334215]\n [0.01712967]\n [0.5485621 ]\n [0.0209864 ]\n [0.87410927]\n [0.02326159]\n [0.03964468]\n [0.02306768]\n [0.02364106]\n [0.01940462]\n [0.01761952]\n [0.01443304]\n [0.89661646]\n [0.01679474]\n [0.0145347 ]\n [0.05153647]\n [0.01626348]\n [0.8806211 ]\n [0.01438587]\n [0.85353965]\n [0.01556376]\n [0.41885698]\n [0.01954851]\n [0.02395438]\n [0.75343317]\n [0.5275238 ]\n [0.0188675 ]\n [0.81042045]\n [0.01722175]\n [0.01633538]\n [0.02131261]\n [0.04127194]\n [0.11857851]\n [0.88179475]\n [0.0170991 ]\n [0.02070215]\n [0.05838896]\n [0.07376051]\n [0.02859217]\n [0.03308121]\n [0.01665883]\n [0.04109595]\n [0.8907422 ]\n [0.01851279]\n [0.01985775]\n [0.0312267 ]\n [0.02918242]\n [0.25493032]\n [0.01650057]\n [0.8568581 ]\n [0.01890028]\n [0.01500835]\n [0.01673715]\n [0.01192124]\n [0.02067805]\n [0.02213231]\n [0.01968274]\n [0.08268975]\n [0.01664862]\n [0.3140889 ]\n [0.03516124]\n [0.90721893]\n [0.0209742 ]\n [0.01737805]\n [0.02920987]\n [0.87114275]\n [0.04320088]\n [0.03391434]\n [0.02025487]\n [0.01606518]\n [0.0219906 ]\n [0.11364707]\n [0.01868961]\n [0.02263142]\n [0.01598598]\n [0.01459133]\n [0.01828781]\n [0.02133052]\n [0.02845358]\n [0.01333276]\n [0.01141271]\n [0.54382426]\n [0.01446507]\n [0.01547299]\n [0.02595886]\n [0.01844395]\n [0.01546609]\n [0.01375025]\n [0.0188861 ]\n [0.01261043]\n [0.01677917]\n [0.1335533 ]\n [0.01814074]\n [0.01394072]\n [0.6318992 ]\n [0.01702803]\n [0.01820306]\n [0.03449478]\n [0.02596183]\n [0.8622555 ]\n [0.01520637]\n [0.01983409]\n [0.01734927]\n [0.02090654]\n [0.01163578]\n [0.02573694]\n [0.01196483]\n [0.01259562]\n [0.02056458]\n [0.84228015]\n [0.04348027]\n [0.01550572]\n [0.0234539 ]\n [0.03515706]\n [0.0744939 ]\n [0.01611001]\n [0.01946055]\n [0.01968229]\n [0.01571125]\n [0.01239698]\n [0.86638856]\n [0.01742919]\n [0.01540925]\n [0.82801497]\n [0.02464041]\n [0.01888794]\n [0.8398886 ]\n [0.9056631 ]\n [0.01808383]\n [0.01772624]\n [0.01955188]\n [0.02010981]\n [0.0171173 ]\n [0.03478482]\n [0.01522172]\n [0.01964781]\n [0.01391175]\n [0.01537034]\n [0.0176929 ]\n [0.13733143]\n [0.02359864]\n [0.04109629]\n [0.01934079]\n [0.01868105]\n [0.01808445]\n [0.01754322]\n [0.01652423]\n [0.01900673]\n [0.89915246]\n [0.10328113]\n [0.02194499]\n [0.04365652]\n [0.81487316]\n [0.02050503]\n [0.01281187]\n [0.03083548]\n [0.02022476]\n [0.01418088]\n [0.01451371]\n [0.01287084]\n [0.17942944]\n [0.01688978]\n [0.89399254]\n [0.01493665]\n [0.01121577]\n [0.01703031]\n [0.01652508]\n [0.02364165]\n [0.01402714]\n [0.01644274]\n [0.01657666]\n [0.01833267]\n [0.02770256]\n [0.88758093]\n [0.02024173]\n [0.0167609 ]\n [0.02448707]\n [0.02063853]\n [0.02175089]\n [0.02350669]\n [0.9016935 ]\n [0.01926084]\n [0.03950336]\n [0.01558064]\n [0.06231353]\n [0.01360466]\n [0.86157113]\n [0.03116728]\n [0.01816138]\n [0.8939498 ]\n [0.01465347]\n [0.04430675]\n [0.0176894 ]\n [0.82667977]\n [0.0165435 ]\n [0.02164298]\n [0.01367503]\n [0.03185142]\n [0.01915559]\n [0.9079044 ]\n [0.01500907]\n [0.01721913]\n [0.01978786]\n [0.01795039]\n [0.01863022]\n [0.01618821]\n [0.01818164]\n [0.01781169]\n [0.01759507]\n [0.9040691 ]\n [0.9060436 ]\n [0.86440474]\n [0.0177882 ]\n [0.0195084 ]\n [0.01195723]\n [0.01763848]\n [0.02062599]\n [0.02234896]\n [0.01710118]\n [0.01809009]\n [0.0525534 ]\n [0.0213794 ]\n [0.01685935]\n [0.7732285 ]\n [0.84901685]\n [0.0215915 ]\n [0.27944162]\n [0.01340571]\n [0.8768296 ]\n [0.01619957]\n [0.02001882]\n [0.0138458 ]\n [0.02320132]\n [0.08593778]\n [0.01698627]\n [0.04142704]\n [0.01548475]\n [0.8388435 ]\n [0.02332653]\n [0.8497144 ]\n [0.02329025]\n [0.02447479]\n [0.01651397]\n [0.01626558]\n [0.02544026]\n [0.03565602]\n [0.8849749 ]\n [0.7650045 ]\n [0.9125044 ]\n [0.02375937]\n [0.01866385]\n [0.01714204]\n [0.822946  ]\n [0.0184228 ]\n [0.82298994]\n [0.84846   ]\n [0.01724061]\n [0.02143935]\n [0.01978291]\n [0.87531096]\n [0.01519702]\n [0.01604274]\n [0.03229978]\n [0.22989632]\n [0.01187909]\n [0.01957812]\n [0.01641619]\n [0.0452484 ]\n [0.04280553]\n [0.02023604]\n [0.01796141]\n [0.77790135]\n [0.02123143]\n [0.01684645]\n [0.01608852]\n [0.03899096]\n [0.01855464]\n [0.03140216]\n [0.5018995 ]\n [0.0169172 ]\n [0.02164507]\n [0.01774671]\n [0.6383755 ]\n [0.02092458]\n [0.02046915]\n [0.0213086 ]\n [0.01834447]\n [0.03351135]\n [0.8584812 ]\n [0.01936278]\n [0.02113869]\n [0.01575792]\n [0.01659212]\n [0.01659701]\n [0.82644534]\n [0.7587435 ]\n [0.0148608 ]\n [0.01832607]\n [0.06617329]\n [0.0399178 ]\n [0.0217072 ]\n [0.6935017 ]\n [0.01748075]\n [0.01922291]\n [0.01897097]\n [0.01719042]\n [0.01435117]\n [0.83177835]\n [0.02703265]\n [0.01937408]\n [0.01930665]\n [0.02750564]\n [0.02800633]\n [0.02200779]\n [0.0194324 ]\n [0.02207379]\n [0.86837065]\n [0.01924207]\n [0.06295028]\n [0.02224185]\n [0.02797688]\n [0.01512066]\n [0.01470317]\n [0.02709018]\n [0.03062905]\n [0.03155766]\n [0.9001065 ]\n [0.01703008]\n [0.06298063]\n [0.5271782 ]\n [0.0388883 ]\n [0.19416039]\n [0.01646056]\n [0.0173468 ]\n [0.02143153]\n [0.02010475]\n [0.02987814]\n [0.01655735]\n [0.01591237]\n [0.01742623]\n [0.02657996]\n [0.02133824]\n [0.01144366]\n [0.82344806]\n [0.01141321]\n [0.0621502 ]\n [0.12699188]\n [0.01822718]\n [0.01736107]\n [0.02092014]\n [0.08501483]\n [0.03105514]\n [0.02274642]\n [0.01670314]\n [0.01583779]\n [0.02940708]\n [0.01814406]\n [0.01501866]\n [0.01535796]\n [0.8642784 ]\n [0.02793068]\n [0.8023749 ]\n [0.23339956]\n [0.0162973 ]\n [0.0182107 ]\n [0.08073867]\n [0.27690664]\n [0.01711102]\n [0.01675239]\n [0.01443283]\n [0.02566703]\n [0.69086266]\n [0.8954691 ]\n [0.02393571]\n [0.06665132]\n [0.01756416]\n [0.01779983]\n [0.02233924]\n [0.0177755 ]\n [0.039785  ]\n [0.04063393]\n [0.10561055]\n [0.81814265]\n [0.02014368]\n [0.01916575]\n [0.8106497 ]\n [0.8908563 ]\n [0.016152  ]\n [0.03610519]\n [0.0152749 ]\n [0.01557145]\n [0.21043497]\n [0.01485195]\n [0.02329974]\n [0.6275575 ]\n [0.0228799 ]\n [0.01436855]\n [0.88733774]\n [0.01841341]\n [0.06958358]\n [0.0155027 ]\n [0.78011185]\n [0.02082736]\n [0.01506528]\n [0.01441252]\n [0.0345775 ]\n [0.01978188]\n [0.02086755]\n [0.01791088]\n [0.02413026]\n [0.8097705 ]\n [0.0547662 ]\n [0.01665713]\n [0.01610929]\n [0.01768808]\n [0.02596883]\n [0.01849288]\n [0.01573369]\n [0.01565069]\n [0.01708858]\n [0.0182739 ]\n [0.02005858]\n [0.0268317 ]\n [0.01592668]\n [0.02052663]\n [0.01281695]\n [0.02196256]\n [0.01906924]\n [0.8658773 ]\n [0.80638313]\n [0.01565486]\n [0.04829261]\n [0.01905618]\n [0.02179572]\n [0.7318352 ]\n [0.02217418]\n [0.8607284 ]\n [0.03933986]\n [0.8885219 ]\n [0.0160301 ]\n [0.02360536]\n [0.8790379 ]\n [0.82509595]\n [0.04883668]\n [0.02936812]\n [0.02214554]\n [0.0211316 ]\n [0.01900829]\n [0.8363232 ]\n [0.01221263]\n [0.78315836]\n [0.14855386]\n [0.9017482 ]\n [0.0221747 ]\n [0.01698137]\n [0.87496024]\n [0.0229092 ]\n [0.10409214]\n [0.02001712]\n [0.892172  ]\n [0.8872056 ]\n [0.01835239]\n [0.01828646]\n [0.7666835 ]\n [0.7611164 ]\n [0.01890776]\n [0.8488275 ]\n [0.03041629]\n [0.01716486]\n [0.01797756]\n [0.02827529]\n [0.02065037]\n [0.02894123]\n [0.26538062]\n [0.8433339 ]\n [0.08125339]\n [0.01582639]\n [0.01717702]\n [0.01418981]\n [0.8453577 ]\n [0.89213735]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_test = [int(i>0.5) for i in results_test]\nlen(results_test)","execution_count":119,"outputs":[{"output_type":"execute_result","execution_count":119,"data":{"text/plain":"571"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_nn = pd.read_csv('../input/zsdataset/test.csv',encoding = 'ISO-8859-1')\nsubmission = pd.DataFrame()\nsubmission['Index'] = submission_nn['Index']\nsubmission['Patient_Tag'] = results_test\nsubmission.to_csv('submission_nn.csv',index = False)","execution_count":120,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}